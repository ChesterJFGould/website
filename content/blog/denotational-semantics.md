---
title: "Denotational Semantics and FFIs"
date: 2023-10-25T16:00:21-07:00
draft: true
---

# C Compilers

Traditionally we think of a C compiler as taking some piece of C code and
producing some assembly code.
Of course, this isn't just any old assembly code, we expect the assembly code
to reflect in some way what we wanted the source code to do.
We call this idea of what some piece of C code will do the *semantics* of C.
A lot of the time when writing C code, we actually think about what the code
will do in terms of the assembly code.
One might almost be tempted to say that the C code *denotes* the assembly code
which the compilers produces.
We call this kind of meaning denotational semantics, since we give meaning to
the C code in terms of the meaning of some piece of assembly code.
In this case, we think of the compiler as almost giving the C code denotational
semantics in terms of assembly.
Of course, in practice it's quite difficult to tell what our C compiler will
produce (especially with optimizations turned on), but even in that case we
expect the compiler output to somehow behave in the same way as the assembly
code we might expect ([although not always](https://blog.llvm.org/2011/05/what-every-c-programmer-should-know.html)).

# Foreigners

Ok, so we can go from C to assembly in some way that mostly makes sense, so
what?
Well luckily we have these cool machines which give assembly denotational
semantics in terms of real life, so we can give C real life semantics by going
from C to assembly with a compiler, then assembly to real life with one of these
marvelous machines.
But also, there are other languages which can compile to assembly, like Rust.
Since both Rust and C can be given meaning in terms of assembly, we could
imagine giving meaning to running some Rust code inside of some C code (or vice
versa) in terms of how their respective assembly language representations
interact.
In fact we don't even need to imagine this, using a foreign function interface
we can call Rust code from C code, and C code from Rust code.

# Racket

This ability to have different languages interact by giving semantics in
assembly is pretty cool, but why does it have to be assembly?
This is basically the defining question of the [racket](https://racket-lang.org/)
system.
In racket (the system), we can give languages semantics in terms of the racket
core language (which itself has semantics in terms of real life) and then give
semantics to the interaction of these languages in terms of how they interact
inside of the racket core.
Confusingly, there's a language defined in the racket system which is also
called racket (picture C++ but Scheme++).
This actually works pretty well, for instance I can be writing a compiler in
racket (the language), decide I'd like some type checking please, write a
subcomponent in typed/racket, then call the typed/racket code from the normal
racket code and have everything work out.

# Guarantees

These ideas are all well and good, instead of directly giving a language real
life semantics by building a special machine to run it, we can just give it
denotational semantics in another language which itself has real life semantics.
However, once we want to let two different languages interact by compiling them
to into the same language we encounter a problem, what exactly does an
expression in a language get compiled into?
We must have some idea, for instance a racket function should be compiled into a
racket core function, but in the general case we need to rely on good language
documentation and trial and error to know how to refer to one language from
another.
The problem here is that we have no guarantee about what sort of code will be
generated by the compiler, only that some code will be generated.
There is a better way and it involves types...

# Dependent Racket

Consider some future where we have a version of racket with dependent types.
Since we don't have it (yet), I'll be using Idris2 as a proxy, but I aim to
demonstrate that dependent racket would in fact have a greater ability to share
code between languages than the present dynamic racket.

As a simple example of this, we'll be looking at two very simple languages.
They'll both have integer literals, function application, and one will have
the addition function while the other gets the subtraction function.
Because of this let's call them AddLang and SubLang.
Our goal will be to import AddLang addition into SubLang and vice versa.
To model importing we'll also give each language an import form which will
embed some (almost) arbitrary idris expression into the language.
The Idris data types representing these two languages look like this:

```
data SimpleType : Type where
    IntT : SimpleType
    FunT : SimpleType -> SimpleType -> SimpleType

data AddExpr : SimpleType -> Type where
    IntLitA : Int -> AddExpr IntT
    AddA : AddExpr (FunT IntT (FunT IntT IntT))
    AppA : AddExpr (FunT a b) -> AddExpr a -> AddExpr b
    ImportA : {A : Type} ->
              {auto prf : IsSimpleType A} ->
              (a : A) ->
              AddExpr (inv_interp_st prf)

data SubExpr : SimpleType -> Type where
    IntLitS : Int -> SubExpr IntT
    SubS : SubExpr (FunT IntT (FunT IntT IntT))
    AppS : SubExpr (FunT a b) -> SubExpr a -> SubExpr b
    ImportS : {A : Type} ->
              {auto prf : IsSimpleType A} ->
              (a : A) ->
              SubExpr (inv_interp_st prf)
```

The first thing to note is that each of the expression data types is indexed by
SimpleType.
This is meant to represent the type of an expression, so for instance
`IntLitA 10` has type `AddExpr IntT`, and `AppS SubS (IntLitS 5)` has type
`SubExpr (FunT IntT IntT)`.

The second thing to note are the weird types of the import forms.
At first glance we might expect them to look like `ImportA : {A : Type} -> (a : A) -> AddExpr A`,
but there are two problems with this.
The most immediate one is that `A` is not a `SimpleType`, but just a `Type`.
This is the problem that `inv_interp_st` will solve, it will generate the
`SimpleType` which corresponds to `A` (so if `A` is `Int`, the it will generate `IntT`, etc.).
The second problem is that not all Idris types can be turned into simple
types, for example it wouldn't really make sense to be able to import some boolean
Idris value into our languages since they don't have booleans in their type systems.
This is the problem that `{auto prf : IsSimpleType A}` solves.
A value of type `IsSimpleType A` will constitute a proof that `A` can be
turned into a `SimpleType` (the `auto` prefix indicating that Idris should try
its best to generate this proof).
The data type description for `IsSimpleType` looks like this:

```
data IsSimpleType : Type -> Type where
     IsInt : IsSimpleType Int
     IsFun : {a_proof : IsSimpleType a} ->
             {b_proof : IsSimpleType b} ->
             IsSimpleType (a -> b)
```

This should be pretty straight forward, `IsInt` proves that `IsSimpleType Int`
is true, and `IsFun` proves that `IsSimpleType (a -> b)` is true as long as we
know that both `IsSimpleType a` and `IsSimpleType b` are true.
Now that we've seen `IsSimpleType`, we can look at the definition for
`inv_interp_st`.

```
inv_interp_st : {t : Type} -> IsSimpleType t -> SimpleType
inv_interp_st IsInt = IntT
inv_interp_st (IsFun {a_proof} {b_proof}) =
    FunT (inv_interp_st a_proof) (inv_interp_st b_proof)
```

As stated previously, `inv_interp_st` should generate the `SimpleType`
corresponding to some type `t` (note: we haven't gotten to why it's *called*
`inv_interp_st`), but note that we're not pattern matching over the type `t`,
but the proof that the type is a simple type.
This is not some fundamental thing, we could define it by pattern matching over
`t`, but it's a bit simpler to just pattern match over the proof since it closely
mirrors the definition of `SimpleType`.

Now we can get to the interesting part, we'll have two functions `eval_add`
and `eval_sub` which will embed AddLang and SubLang expressions into Idris.
Some examples would be `eval_add (IntLitA 10)` returning `10`, and
`eval_sub SubS` returning the Idris function `-`.
In general we want an expression with type `IntT` to evaluate to an Idris `Int`,
and an expression with type `FunT a b` to evaluate to some Idris function
`a' -> b'`, where `a'` and `b'` are the interpretations of `a` and `b`.
We can capture this behaviour with the following definition,

```
interp_st : SimpleType -> Type
interp_st IntT = Int
interp_st (FunT a b) = (interp_st a) -> (interp_st b)
```

And using this definition we can give types to our eval functions,

```
eval_add : AddExpr t -> interp_st t

eval_sub : SubExpr t -> interp_st t
```

These types formalize our intuition from before that the eval functions should
have different return types based on the input expression (e.g. eval of a int
lit should return an `Int`, eval of one of our arithmetic functions should
return an `Int -> Int -> Int`).

Now let's go through the definitions case by case
